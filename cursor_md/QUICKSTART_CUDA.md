# CUDA Ray-based Renderer - ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ

## ğŸ“Œ TL;DR

```bash
# 1. ì„¤ì¹˜
./install_cuda_renderer.sh

# 2. í…ŒìŠ¤íŠ¸
python test_cuda_renderer.py

# 3. ì‚¬ìš© - configs/default.pyì—ì„œ í•œ ì¤„ë§Œ ìˆ˜ì •
self.use_cuda_renderer = True

# 4. ì‹¤í–‰ (ê¸°ì¡´ ì½”ë“œ ê·¸ëŒ€ë¡œ!)
python main.py
```

## ğŸ¯ í•µì‹¬ ê°œë…

### ë¬¸ì œ: Computational Bottleneck

```python
# ê¸°ì¡´ ë°©ì‹ - ëŠë¦¼! ğŸ’€
for all_gaussians:           # 5,000ê°œ
    for all_sample_points:   # 1,024 Ã— 200 = 204,800ê°œ
        compute_contribution()
# â†’ 1,024,000,000 ê³„ì‚°!
```

### í•´ê²°: Ray-based Rendering

```python
# CUDA ë°©ì‹ - ë¹ ë¦„! âš¡
for each_ray:                # 1,024ê°œ
    filter_gaussians()       # ~50ê°œë§Œ ì„ íƒ
    for r_samples:           # 200ê°œ
        compute_contribution()
# â†’ ~10,240,000 ê³„ì‚°!
# â†’ 100ë°° ê³„ì‚°ëŸ‰ ê°ì†Œ!
```

## ğŸ”¥ ì„±ëŠ¥

| í•­ëª© | ê¸°ì¡´ | CUDA | ê°œì„  |
|------|------|------|------|
| **ì†ë„** | 450ms | 12ms | **37Ã—** |
| **ë©”ëª¨ë¦¬** | 8.2GB | 0.6GB | **13Ã—** |
| **Gaussian ìˆ˜** | ~5k | ~50k | **10Ã—** |

## ğŸ“ ìƒì„±ëœ íŒŒì¼ êµ¬ì¡°

```
NLOS-Gaussian/
â”œâ”€â”€ cuda_renderer/               # ìƒˆë¡œ ìƒì„±ë¨! âœ¨
â”‚   â”œâ”€â”€ __init__.py             # Python wrapper
â”‚   â”œâ”€â”€ setup.py                # ë¹Œë“œ ìŠ¤í¬ë¦½íŠ¸
â”‚   â”œâ”€â”€ include/
â”‚   â”‚   â”œâ”€â”€ cuda_utils.cuh      # CUDA utilities
â”‚   â”‚   â”œâ”€â”€ ray_aabb.h          # Ray-AABB intersection
â”‚   â”‚   â””â”€â”€ volume_renderer.h   # Volume rendering
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ bindings.cpp        # PyTorch binding
â”‚       â”œâ”€â”€ ray_aabb.cu         # Gaussian filtering
â”‚       â””â”€â”€ volume_renderer.cu  # Ray rendering kernel
â”‚
â”œâ”€â”€ gaussian_model/
â”‚   â”œâ”€â”€ gaussian_model.py       # ê¸°ì¡´ ì½”ë“œ
â”‚   â””â”€â”€ rendering_cuda.py       # ìƒˆë¡œ ì¶”ê°€! âœ¨
â”‚
â”œâ”€â”€ configs/default.py          # ìˆ˜ì •ë¨! use_cuda_renderer ì¶”ê°€
â”œâ”€â”€ nlos_helpers.py             # ìˆ˜ì •ë¨! CUDA ì§€ì› ì¶”ê°€
â”‚
â”œâ”€â”€ install_cuda_renderer.sh    # ìƒˆë¡œ ì¶”ê°€! âœ¨
â”œâ”€â”€ test_cuda_renderer.py       # ìƒˆë¡œ ì¶”ê°€! âœ¨
â”œâ”€â”€ QUICKSTART_CUDA.md          # ì´ íŒŒì¼!
â””â”€â”€ README_CUDA_ACCELERATION.md # ìƒì„¸ ê°€ì´ë“œ
```

## ğŸš€ ë‹¨ê³„ë³„ ì„¤ì¹˜

### Step 1: í™˜ê²½ í™•ì¸

```bash
# CUDA ì„¤ì¹˜ í™•ì¸
nvcc --version
# ì¶œë ¥ ì˜ˆ: Cuda compilation tools, release 11.x

# PyTorch CUDA ì§€ì› í™•ì¸
python -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"
# ì¶œë ¥ ì˜ˆ: CUDA: True
```

### Step 2: CUDA Extension ë¹Œë“œ

```bash
# ë°©ë²• 1: ìë™ ì„¤ì¹˜ (ê¶Œì¥)
./install_cuda_renderer.sh

# ë°©ë²• 2: ìˆ˜ë™ ì„¤ì¹˜
cd cuda_renderer
python setup.py install
cd ..
```

ë¹Œë“œ ì‹œê°„: ì•½ 2-5ë¶„ (ì²˜ìŒ í•œ ë²ˆë§Œ)

### Step 3: ì„¤ì¹˜ í™•ì¸

```bash
python test_cuda_renderer.py
```

**ì„±ê³µ ì‹œ ì¶œë ¥**:
```
======================================
Test 1: Import CUDA Renderer
======================================
âœ“ CUDA renderer imported successfully
âœ“ CUDA available: True
âœ“ Renderer instance created

...

âœ“ All tests passed!
```

## âš™ï¸ ì‚¬ìš© ë°©ë²•

### Option 1: Config íŒŒì¼ ìˆ˜ì • (ê¶Œì¥)

`configs/default.py`:
```python
class Config:
    def __init__(self):
        # ... ê¸°ì¡´ ì„¤ì • ...
        
        # ì´ í•œ ì¤„ë§Œ ì¶”ê°€/ìˆ˜ì •
        self.use_cuda_renderer = True
```

ê·¸ë¦¬ê³  ê¸°ì¡´ëŒ€ë¡œ ì‹¤í–‰:
```bash
python main.py
```

### Option 2: ëŸ°íƒ€ì„ì—ì„œ ì„¤ì •

```python
from configs.default import Config, OptimizationParams

args = Config()
args.use_cuda_renderer = True  # CUDA í™œì„±í™”

train(args, optim_args, device)
```

### Option 3: ìˆ˜ë™ ì‚¬ìš©

```python
from gaussian_model.rendering_cuda import create_cuda_renderer

renderer = create_cuda_renderer()

result, histogram = renderer.render_transient(
    gaussian_model=model,
    camera_pos=camera_position,
    theta_range=(theta_min, theta_max),
    phi_range=(phi_min, phi_max),
    r_range=(r_min, r_max),
    num_theta=32,
    num_phi=32,
    num_r=200,
    c=1.0,
    deltaT=0.01
)
```

## ğŸ¨ ì‹¤ì „ ì˜ˆì œ

### ì˜ˆì œ 1: ê¸°ë³¸ í•™ìŠµ

```python
from configs.default import Config, OptimizationParams
from main import train
import torch

# Config
args = Config()
args.use_cuda_renderer = True
args.datadir = './data/zaragozadataset/zaragoza256_preprocessed.mat'
args.num_sampling_points = 32
args.init_gaussian_num = 5000

optim_args = OptimizationParams()
optim_args.iterations = 50_000

# Device
device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")

# Train
train(args, optim_args, device)
```

### ì˜ˆì œ 2: ì„±ëŠ¥ ë¹„êµ

```python
import time
import torch

# ë™ì¼í•œ ì„¤ì •ìœ¼ë¡œ ë‘ ë°©ì‹ ë¹„êµ
def benchmark(use_cuda):
    args.use_cuda_renderer = use_cuda
    
    start = time.time()
    for _ in range(10):
        loss, equal_loss = compute_loss(
            args, model, data_kwargs, optim_kwargs, device
        )
        loss.backward()
    torch.cuda.synchronize()
    elapsed = time.time() - start
    
    return elapsed / 10

# ì¸¡ì •
time_standard = benchmark(False)
time_cuda = benchmark(True)

print(f"Standard: {time_standard*1000:.1f} ms/iter")
print(f"CUDA:     {time_cuda*1000:.1f} ms/iter")
print(f"Speedup:  {time_standard/time_cuda:.1f}x")
```

### ì˜ˆì œ 3: ë©”ëª¨ë¦¬ ëª¨ë‹ˆí„°ë§

```python
import torch

def measure_memory(use_cuda):
    torch.cuda.reset_peak_memory_stats()
    args.use_cuda_renderer = use_cuda
    
    # Forward pass
    loss, _ = compute_loss(args, model, data_kwargs, optim_kwargs, device)
    
    peak_mem = torch.cuda.max_memory_allocated() / 1024**3
    return peak_mem

mem_standard = measure_memory(False)
mem_cuda = measure_memory(True)

print(f"Standard: {mem_standard:.2f} GB")
print(f"CUDA:     {mem_cuda:.2f} GB")
print(f"Reduction: {mem_standard/mem_cuda:.1f}x")
```

## ğŸ”§ ìµœì í™” íŒ

### Tip 1: Gaussian ìˆ˜ ì¡°ì ˆ

```python
# Scene complexityì— ë”°ë¼ ì¡°ì ˆ
args.init_gaussian_num = 2000   # Simple scene
args.init_gaussian_num = 5000   # Normal scene (ì¶”ì²œ)
args.init_gaussian_num = 10000  # Complex scene
```

### Tip 2: Angular Resolution

```python
# í’ˆì§ˆ vs ì†ë„ trade-off
args.num_sampling_points = 16   # Fast (256 rays)
args.num_sampling_points = 32   # Balanced (1024 rays) ì¶”ì²œ
args.num_sampling_points = 64   # High quality (4096 rays)
```

### Tip 3: Ïƒ Threshold

```python
# Gaussian filtering ì •í™•ë„
renderer = create_cuda_renderer(
    sigma_threshold=2.5  # Fast, less accurate
)
renderer = create_cuda_renderer(
    sigma_threshold=3.0  # Balanced (ì¶”ì²œ)
)
renderer = create_cuda_renderer(
    sigma_threshold=4.0  # Slow, more accurate
)
```

## â— ë¬¸ì œ í•´ê²°

### Q1: "CUDA renderer not available"

**A**: Extensionì´ ì„¤ì¹˜ë˜ì§€ ì•ŠìŒ

```bash
cd cuda_renderer
python setup.py install --force
python -c "from cuda_renderer import NLOSGaussianRenderer"
```

### Q2: "CUDA out of memory"

**A**: GPU ë©”ëª¨ë¦¬ ë¶€ì¡±

```python
# í•´ê²° 1: ìƒ˜í”Œë§ ì¤„ì´ê¸°
args.num_sampling_points = 16  # 32 â†’ 16

# í•´ê²° 2: Gaussian ìˆ˜ ì¤„ì´ê¸°
args.init_gaussian_num = 2000  # 5000 â†’ 2000

# í•´ê²° 3: Batch í¬ê¸° ì¡°ì ˆ
# (í˜„ì¬ êµ¬í˜„ì—ì„œëŠ” í•œ ë²ˆì— í•˜ë‚˜ì˜ ì¹´ë©”ë¼ ìœ„ì¹˜ë§Œ ì²˜ë¦¬)
```

### Q3: ë¹Œë“œ ì‹¤íŒ¨ "nvcc not found"

**A**: CUDA í™˜ê²½ë³€ìˆ˜ ì„¤ì •

```bash
export CUDA_HOME=/usr/local/cuda
export PATH=$CUDA_HOME/bin:$PATH
export LD_LIBRARY_PATH=$CUDA_HOME/lib64:$LD_LIBRARY_PATH

# ì¬ì‹œë„
./install_cuda_renderer.sh
```

### Q4: ê²°ê³¼ê°€ ê¸°ì¡´ê³¼ ë‹¤ë¦„

**A**: ì •ìƒì…ë‹ˆë‹¤. ì•½ê°„ì˜ ì°¨ì´ëŠ” ì˜ˆìƒë¨

- Floating-point ì •ë°€ë„
- Gaussian filtering (ì¼ë¶€ ì‘ì€ ê¸°ì—¬ë„ ì œì™¸)
  
ë” ì •í™•í•œ ê²°ê³¼ë¥¼ ì›í•˜ë©´:
```python
renderer = create_cuda_renderer(sigma_threshold=4.0)
```

## ğŸ“Š ì„±ëŠ¥ í”„ë¡œíŒŒì¼ë§

```python
import torch.cuda.profiler as profiler
import torch.autograd.profiler as autograd_profiler

with autograd_profiler.profile(use_cuda=True) as prof:
    loss, _ = compute_loss(args, model, data_kwargs, optim_kwargs, device)
    loss.backward()

print(prof.key_averages().table(sort_by="cuda_time_total"))
```

## ğŸ“ ì‘ë™ ì›ë¦¬ (ê°„ë‹¨íˆ)

### 1. Ray Generation
```
ê° (Î¸, Ï†) â†’ ray direction
Camera position â†’ ray origin
```

### 2. Gaussian Filtering [CUDA]
```
for each ray:
    for each gaussian:
        if ray intersects gaussian_bbox:
            add to filtered_list
```

### 3. Volume Rendering [CUDA]
```
for each ray:
    for filtered gaussians:
        for each r sample:
            density += gaussian_pdf(r) * opacity
            rho_density += density * albedo(view_dir)
```

### 4. Integration [Python]
```
result *= sin(Î¸) / rÂ²  # attenuation
histogram = sum over (Î¸, Ï†)  # angular integration
```

## ğŸ“š ì¶”ê°€ ìë£Œ

- **ìƒì„¸ ê°€ì´ë“œ**: `README_CUDA_ACCELERATION.md`
- **CUDA êµ¬í˜„**: `cuda_renderer/README.md`
- **ë…¼ë¬¸**: "Don't Splat Your Gaussians"

## ğŸ’¡ ë‹¤ìŒ ë‹¨ê³„

1. âœ… CUDA renderer ì„¤ì¹˜
2. âœ… ê¸°ì¡´ ì½”ë“œë¡œ í…ŒìŠ¤íŠ¸
3. [ ] ì„±ëŠ¥ ì¸¡ì • ë° ë¹„êµ
4. [ ] í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
5. [ ] Large-scale scene ì‹¤í—˜

---

**ì§ˆë¬¸ì´ë‚˜ ì´ìŠˆê°€ ìˆìœ¼ë©´ GitHub Issuesë¥¼ ì´ìš©í•´ì£¼ì„¸ìš”!**

Happy NLOS Reconstruction! ğŸ‰


